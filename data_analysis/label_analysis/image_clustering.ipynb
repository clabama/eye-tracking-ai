{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a71f7ce",
   "metadata": {},
   "source": [
    "# Image clustering and label mapping (per_image_descriptive_summary)\n",
    "\n",
    "This notebook clusters images using features from `per_image_descriptive_summary.csv` and maps/apply labels via `labels_per_id.csv`.\n",
    "\n",
    "It will:\n",
    "- Load and prepare per-image features.\n",
    "- Standardize and cluster images (K-Means by default).\n",
    "- Visualize clusters in 2D (PCA).\n",
    "- Join labels by `image_id` from `labels_per_id.csv`.\n",
    "- Provide a simple override workflow to apply corrected labels and save them for later comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2493d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\n",
      "Summary CSV: c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\descriptive_analysis\\per_image_descriptive_summary.csv (exists=True)\n",
      "Labels CSV: c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\labels_per_id.csv (exists=True)\n",
      "Outputs: c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\n"
     ]
    }
   ],
   "source": [
    "# Setup and paths\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, normalize as sk_normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "def find_project_root(start: Path):\n",
    "    for cand in [start, *start.parents]:\n",
    "        if (cand / 'labels_per_id.csv').exists() or (cand / 'data_analysis').exists():\n",
    "            return cand\n",
    "    return start\n",
    "\n",
    "nb_dir = Path.cwd()\n",
    "project_root = find_project_root(nb_dir)\n",
    "summary_csv = project_root / 'data_analysis' / 'descriptive_analysis' / 'per_image_descriptive_summary.csv'\n",
    "labels_csv = project_root / 'labels_per_id.csv'\n",
    "out_dir = project_root / 'data_analysis' / 'label_analysis'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Project root: {project_root}')\n",
    "print(f'Summary CSV: {summary_csv} (exists={summary_csv.exists()})')\n",
    "print(f'Labels CSV: {labels_csv} (exists={labels_csv.exists()})')\n",
    "print(f'Outputs: {out_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7302621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>number_of_fixations</th>\n",
       "      <th>view_time_total_sum</th>\n",
       "      <th>fixation_duration_mean_weighted</th>\n",
       "      <th>fixation_duration_median_approx</th>\n",
       "      <th>scanpath_length_mean</th>\n",
       "      <th>BCEA_68_mean</th>\n",
       "      <th>BCEA_95_mean</th>\n",
       "      <th>primary_label_top</th>\n",
       "      <th>pupil_size_norm_mean</th>\n",
       "      <th>pupil_size_norm_std</th>\n",
       "      <th>fix_dur_mean_first_third</th>\n",
       "      <th>fix_dur_mean_last_third</th>\n",
       "      <th>n_fix_first_third</th>\n",
       "      <th>n_fix_last_third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>1159</td>\n",
       "      <td>425375.042</td>\n",
       "      <td>284.329020</td>\n",
       "      <td>232.36300</td>\n",
       "      <td>3688.463661</td>\n",
       "      <td>72008.690066</td>\n",
       "      <td>189496.552805</td>\n",
       "      <td>meme</td>\n",
       "      <td>2.101475e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>274.590950</td>\n",
       "      <td>311.450110</td>\n",
       "      <td>406</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>1284</td>\n",
       "      <td>452560.267</td>\n",
       "      <td>274.577679</td>\n",
       "      <td>232.92700</td>\n",
       "      <td>2665.561573</td>\n",
       "      <td>60359.429235</td>\n",
       "      <td>158840.603249</td>\n",
       "      <td>meme</td>\n",
       "      <td>-2.377767e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>270.570046</td>\n",
       "      <td>286.048076</td>\n",
       "      <td>440</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>1110</td>\n",
       "      <td>411435.771</td>\n",
       "      <td>296.863510</td>\n",
       "      <td>245.25175</td>\n",
       "      <td>3022.834081</td>\n",
       "      <td>40009.274302</td>\n",
       "      <td>105287.563953</td>\n",
       "      <td>meme</td>\n",
       "      <td>2.772367e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>261.323237</td>\n",
       "      <td>375.535697</td>\n",
       "      <td>415</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>1354</td>\n",
       "      <td>469790.081</td>\n",
       "      <td>280.162546</td>\n",
       "      <td>216.58800</td>\n",
       "      <td>3536.890776</td>\n",
       "      <td>87693.362497</td>\n",
       "      <td>230772.006571</td>\n",
       "      <td>meme</td>\n",
       "      <td>-7.328157e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>269.514004</td>\n",
       "      <td>306.053531</td>\n",
       "      <td>477</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>1359</td>\n",
       "      <td>460515.114</td>\n",
       "      <td>265.496762</td>\n",
       "      <td>216.43100</td>\n",
       "      <td>3734.527053</td>\n",
       "      <td>90696.081085</td>\n",
       "      <td>238673.897592</td>\n",
       "      <td>meme</td>\n",
       "      <td>-4.174451e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.631797</td>\n",
       "      <td>281.616679</td>\n",
       "      <td>480</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  number_of_fixations  view_time_total_sum  \\\n",
       "0      001                 1159           425375.042   \n",
       "1      002                 1284           452560.267   \n",
       "2      003                 1110           411435.771   \n",
       "3      004                 1354           469790.081   \n",
       "4      005                 1359           460515.114   \n",
       "\n",
       "   fixation_duration_mean_weighted  fixation_duration_median_approx  \\\n",
       "0                       284.329020                        232.36300   \n",
       "1                       274.577679                        232.92700   \n",
       "2                       296.863510                        245.25175   \n",
       "3                       280.162546                        216.58800   \n",
       "4                       265.496762                        216.43100   \n",
       "\n",
       "   scanpath_length_mean  BCEA_68_mean   BCEA_95_mean primary_label_top  \\\n",
       "0           3688.463661  72008.690066  189496.552805              meme   \n",
       "1           2665.561573  60359.429235  158840.603249              meme   \n",
       "2           3022.834081  40009.274302  105287.563953              meme   \n",
       "3           3536.890776  87693.362497  230772.006571              meme   \n",
       "4           3734.527053  90696.081085  238673.897592              meme   \n",
       "\n",
       "   pupil_size_norm_mean  pupil_size_norm_std  fix_dur_mean_first_third  \\\n",
       "0          2.101475e-16                  1.0                274.590950   \n",
       "1         -2.377767e-16                  1.0                270.570046   \n",
       "2          2.772367e-16                  1.0                261.323237   \n",
       "3         -7.328157e-17                  1.0                269.514004   \n",
       "4         -4.174451e-17                  1.0                255.631797   \n",
       "\n",
       "   fix_dur_mean_last_third  n_fix_first_third  n_fix_last_third  \n",
       "0               311.450110                406               378  \n",
       "1               286.048076                440               434  \n",
       "2               375.535697                415               350  \n",
       "3               306.053531                477               445  \n",
       "4               281.616679                480               435  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "if not summary_csv.exists():\n",
    "    raise FileNotFoundError(f'Missing {summary_csv}')\n",
    "df = pd.read_csv(summary_csv)\n",
    "# Ensure image_id as 3-digit string\n",
    "if 'image_id' in df.columns:\n",
    "    df['image_id'] = df['image_id'].astype(str).str.extract(r'(\\d+)').fillna('').iloc[:,0].str.zfill(3)\n",
    "else:\n",
    "    raise KeyError('image_id column not found in per_image_descriptive_summary.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd967833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used (13): ['number_of_fixations', 'view_time_total_sum', 'fixation_duration_mean_weighted', 'fixation_duration_median_approx', 'scanpath_length_mean', 'BCEA_68_mean', 'BCEA_95_mean', 'pupil_size_norm_mean', 'pupil_size_norm_std', 'fix_dur_mean_first_third'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.431684</td>\n",
       "      <td>0.463348</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.289031</td>\n",
       "      <td>-1.055962</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.957876</td>\n",
       "      <td>-0.728327</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.123038</td>\n",
       "      <td>0.228047</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.336004</td>\n",
       "      <td>0.421475</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2 image_id\n",
       "0 -1.431684  0.463348      001\n",
       "1 -1.289031 -1.055962      002\n",
       "2 -2.957876 -0.728327      003\n",
       "3 -0.123038  0.228047      004\n",
       "4  0.336004  0.421475      005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection and preprocessing\n",
    "# Pick numeric columns automatically, exclude obvious identifiers\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude = {'image_id'}\n",
    "feature_cols = [c for c in num_cols if c not in exclude]\n",
    "if not feature_cols:\n",
    "    raise ValueError('No numeric feature columns found for clustering.')\n",
    "X = df[feature_cols].copy()\n",
    "# Fill missing with column medians\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# 2D projection for visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "Z = pca.fit_transform(X_scaled)\n",
    "print(f'Features used ({len(feature_cols)}):', feature_cols[:10], '...')\n",
    "pd.DataFrame({'PC1': Z[:,0], 'PC2': Z[:,1], 'image_id': df['image_id']}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4eb609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans: k=5, silhouette=0.230\n",
      "Saved centroids -> c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_feature_centroids.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.431684</td>\n",
       "      <td>0.463348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.289031</td>\n",
       "      <td>-1.055962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.957876</td>\n",
       "      <td>-0.728327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.123038</td>\n",
       "      <td>0.228047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336004</td>\n",
       "      <td>0.421475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  cluster       PC1       PC2\n",
       "0      001        1 -1.431684  0.463348\n",
       "1      002        3 -1.289031 -1.055962\n",
       "2      003        3 -2.957876 -0.728327\n",
       "3      004        1 -0.123038  0.228047\n",
       "4      005        1  0.336004  0.421475"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose number of clusters (k) and fit KMeans\n",
    "k = 5  # adjust as needed\n",
    "km = KMeans(n_clusters=k, n_init=25, random_state=42)\n",
    "clusters = km.fit_predict(X_scaled)\n",
    "sil = silhouette_score(X_scaled, clusters) if len(np.unique(clusters)) > 1 else np.nan\n",
    "print(f'KMeans: k={k}, silhouette={sil:.3f}')\n",
    "\n",
    "# Build per-image cluster assignment (include PCA coords for convenience)\n",
    "cluster_df = pd.DataFrame({\n",
    "    'image_id': df['image_id'],\n",
    "    'cluster': clusters,\n",
    "    'PC1': Z[:, 0],\n",
    "    'PC2': Z[:, 1],\n",
    "})\n",
    "\n",
    "# Save centroids in original feature space for reference\n",
    "centroids_scaled = km.cluster_centers_\n",
    "centroids = pd.DataFrame(scaler.inverse_transform(centroids_scaled), columns=feature_cols)\n",
    "centroids.insert(0, 'cluster', np.arange(k))\n",
    "centroids_out = out_dir / 'cluster_feature_centroids.csv'\n",
    "centroids.to_csv(centroids_out, index=False)\n",
    "print(f'Saved centroids -> {centroids_out}')\n",
    "\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0024ab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\image_clusters_pca.png\n"
     ]
    }
   ],
   "source": [
    "# PCA scatter colored by cluster\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(x=Z[:,0], y=Z[:,1], hue=clusters, palette='tab10', s=50, edgecolor='none')\n",
    "for i, img in enumerate(df['image_id']):\n",
    "    plt.text(Z[i,0], Z[i,1], img, fontsize=8, alpha=0.7)\n",
    "plt.title('Images clustered (PCA 2D)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(title='cluster', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "pca_png = out_dir / 'image_clusters_pca.png'\n",
    "plt.savefig(pca_png, dpi=150)\n",
    "plt.close()\n",
    "print(f'Saved {pca_png}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b956b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded: (154, 14)\n",
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\image_clusters_with_labels.csv (rows=152)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>labels_txt</th>\n",
       "      <th>strong_tags</th>\n",
       "      <th>weak_tags</th>\n",
       "      <th>meme</th>\n",
       "      <th>person</th>\n",
       "      <th>politik</th>\n",
       "      <th>ort</th>\n",
       "      <th>text</th>\n",
       "      <th>meme_weight</th>\n",
       "      <th>person_weight</th>\n",
       "      <th>politik_weight</th>\n",
       "      <th>ort_weight</th>\n",
       "      <th>text_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.431684</td>\n",
       "      <td>0.463348</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.289031</td>\n",
       "      <td>-1.055962</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.957876</td>\n",
       "      <td>-0.728327</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.123038</td>\n",
       "      <td>0.228047</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336004</td>\n",
       "      <td>0.421475</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  cluster       PC1       PC2 labels_txt strong_tags weak_tags  \\\n",
       "0      001        1 -1.431684  0.463348       meme        meme       NaN   \n",
       "1      002        3 -1.289031 -1.055962       meme        meme       NaN   \n",
       "2      003        3 -2.957876 -0.728327       meme        meme       NaN   \n",
       "3      004        1 -0.123038  0.228047       meme        meme       NaN   \n",
       "4      005        1  0.336004  0.421475       meme        meme       NaN   \n",
       "\n",
       "   meme  person  politik  ort  text  meme_weight  person_weight  \\\n",
       "0     1       0        0    0     0          1.0            0.0   \n",
       "1     1       0        0    0     0          1.0            0.0   \n",
       "2     1       0        0    0     0          1.0            0.0   \n",
       "3     1       0        0    0     0          1.0            0.0   \n",
       "4     1       0        0    0     0          1.0            0.0   \n",
       "\n",
       "   politik_weight  ort_weight  text_weight  \n",
       "0             0.0         0.0          0.0  \n",
       "1             0.0         0.0          0.0  \n",
       "2             0.0         0.0          0.0  \n",
       "3             0.0         0.0          0.0  \n",
       "4             0.0         0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join labels_per_id.csv by image_id\n",
    "labels_df = None\n",
    "if labels_csv.exists():\n",
    "    labels_df = pd.read_csv(labels_csv)\n",
    "    if 'image_id' in labels_df.columns:\n",
    "        labels_df['image_id'] = labels_df['image_id'].astype(str).str.extract(r'(\\d+)').fillna('').iloc[:,0].str.zfill(3)\n",
    "    else:\n",
    "        for c in ['id','image','img_id']:\n",
    "            if c in labels_df.columns:\n",
    "                labels_df['image_id'] = labels_df[c].astype(str).str.extract(r'(\\d+)').fillna('').iloc[:,0].str.zfill(3)\n",
    "                break\n",
    "    print(f'Labels loaded: {labels_df.shape if labels_df is not None else None}')\n",
    "else:\n",
    "    print('labels_per_id.csv not found; continuing without label join')\n",
    "\n",
    "merged = cluster_df.copy()\n",
    "if labels_df is not None:\n",
    "    merged = merged.merge(labels_df, on='image_id', how='left')\n",
    "merged_out = out_dir / 'image_clusters_with_labels.csv'\n",
    "merged.to_csv(merged_out, index=False)\n",
    "print(f'Saved {merged_out} (rows={len(merged)})')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e61ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_label_crosstab.csv\n"
     ]
    }
   ],
   "source": [
    "# Cluster vs label crosstab (if a label column is present)\n",
    "label_col_guess = None\n",
    "if 'labels_txt' in merged.columns:\n",
    "    label_col_guess = 'labels_txt'\n",
    "elif 'primary_label' in merged.columns:\n",
    "    label_col_guess = 'primary_label'\n",
    "elif 'category' in merged.columns:\n",
    "    label_col_guess = 'category'\n",
    "if label_col_guess:\n",
    "    ct = pd.crosstab(merged['cluster'], merged[label_col_guess])\n",
    "    ct_out = out_dir / 'cluster_label_crosstab.csv'\n",
    "    ct.to_csv(ct_out)\n",
    "    print(f'Saved {ct_out}')\n",
    "    ct\n",
    "else:\n",
    "    print('No obvious label column found to crosstab.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e534a",
   "metadata": {},
   "source": [
    "### Apply/override labels\n",
    "Create a CSV template you can edit (column `applied_label`). Reload it to apply overrides and save a final mapping for downstream use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28ac23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote override template -> c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\label_overrides_template.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>current_label</th>\n",
       "      <th>applied_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>meme</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id current_label applied_label\n",
       "0      001          meme          meme\n",
       "1      002          meme          meme\n",
       "2      003          meme          meme\n",
       "3      004          meme          meme\n",
       "4      005          meme          meme"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create overrides template (one row per image) if not exists\n",
    "template_path = out_dir / 'label_overrides_template.csv'\n",
    "template = merged[['image_id']].drop_duplicates().copy()\n",
    "# carry over existing label guess if available\n",
    "if 'labels_txt' in merged.columns:\n",
    "    template['current_label'] = merged.groupby('image_id')['labels_txt'].first().reindex(template['image_id']).values\n",
    "elif 'primary_label' in merged.columns:\n",
    "    template['current_label'] = merged.groupby('image_id')['primary_label'].first().reindex(template['image_id']).values\n",
    "else:\n",
    "    template['current_label'] = ''\n",
    "template['applied_label'] = template['current_label']\n",
    "if not template_path.exists():\n",
    "    template.to_csv(template_path, index=False)\n",
    "    print(f'Wrote override template -> {template_path}')\n",
    "else:\n",
    "    print(f'Override template already exists: {template_path}')\n",
    "template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeec31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final labels -> c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\image_labels_applied.csv (rows=152)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>cluster</th>\n",
       "      <th>applied_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>1</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002</td>\n",
       "      <td>3</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>3</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>1</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>1</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  cluster applied_label\n",
       "0      001        1          meme\n",
       "1      002        3          meme\n",
       "2      003        3          meme\n",
       "3      004        1          meme\n",
       "4      005        1          meme"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load overrides (edit the CSV externally, then run this cell)\n",
    "overrides = pd.read_csv(out_dir / 'label_overrides_template.csv') if (out_dir / 'label_overrides_template.csv').exists() else template.copy()\n",
    "overrides['image_id'] = overrides['image_id'].astype(str).str.extract(r'(\\d+)').fillna('').iloc[:,0].str.zfill(3)\n",
    "final_map = merged[['image_id','cluster']].drop_duplicates().merge(overrides[['image_id','applied_label']], on='image_id', how='left')\n",
    "final_out = out_dir / 'image_labels_applied.csv'\n",
    "final_map.to_csv(final_out, index=False)\n",
    "print(f'Saved final labels -> {final_out} (rows={len(final_map)})')\n",
    "final_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c448e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16fcde80",
   "metadata": {},
   "source": [
    "## Cluster compositions and feature profiles\n",
    "\n",
    "The next cells visualize cluster sizes and label distributions, then profile each cluster via z-scored feature centroids and auto-generated explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf6f322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_sizes.png\n",
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_label_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Cluster sizes and optional label distribution\n",
    "assert 'cluster_df' in globals(), 'cluster_df missing; run clustering cell first.'\n",
    "\n",
    "# If merged (with labels) exists, use it; else fall back to cluster_df\n",
    "df_for_labels = globals().get('merged', None)\n",
    "if df_for_labels is None:\n",
    "    df_for_labels = cluster_df.copy()\n",
    "\n",
    "# Cluster size counts\n",
    "counts = cluster_df['cluster'].value_counts().sort_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=counts.index.astype(str), y=counts.values, color='steelblue')\n",
    "plt.title('Cluster sizes (image count)')\n",
    "plt.xlabel('cluster')\n",
    "plt.ylabel('images')\n",
    "plt.tight_layout()\n",
    "bar_out = out_dir / 'cluster_sizes.png'\n",
    "plt.savefig(bar_out, dpi=150)\n",
    "plt.close()\n",
    "print(f'Saved {bar_out}')\n",
    "\n",
    "# Label distribution per cluster (if a label column exists)\n",
    "label_col_guess = None\n",
    "for cand in ['applied_label', 'labels_txt', 'primary_label', 'category']:\n",
    "    if cand in df_for_labels.columns:\n",
    "        label_col_guess = cand\n",
    "        break\n",
    "\n",
    "if label_col_guess:\n",
    "    ct = pd.crosstab(df_for_labels['cluster'], df_for_labels[label_col_guess])\n",
    "    plt.figure(figsize=(10, max(4, 0.35*ct.shape[1])))\n",
    "    (ct.T / ct.sum(axis=1)).T.plot(kind='bar', stacked=True, ax=plt.gca(), colormap='tab20')\n",
    "    plt.title(f'Label distribution per cluster ({label_col_guess})')\n",
    "    plt.xlabel('cluster')\n",
    "    plt.ylabel('share')\n",
    "    plt.legend(title=label_col_guess, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    stacked_out = out_dir / 'cluster_label_distribution.png'\n",
    "    plt.savefig(stacked_out, dpi=150)\n",
    "    plt.close()\n",
    "    print(f'Saved {stacked_out}')\n",
    "else:\n",
    "    print('No label column found; skipped label distribution plot.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8abcc039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_feature_profiles_heatmap.png\n",
      "Saved c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\data_analysis\\label_analysis\\cluster_explanations.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>top_positive_features</th>\n",
       "      <th>top_negative_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BCEA_68_mean (+1.19), BCEA_95_mean (+1.19), pu...</td>\n",
       "      <td>fixation_duration_median_approx (-0.72), fix_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fixation_duration_median_approx (+0.76), fix_d...</td>\n",
       "      <td>n_fix_first_third (-0.66), number_of_fixations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>view_time_total_sum (+1.70), n_fix_last_third ...</td>\n",
       "      <td>fix_dur_mean_last_third (-1.23), fixation_dura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fix_dur_mean_last_third (+1.44), fix_dur_mean_...</td>\n",
       "      <td>n_fix_first_third (-1.02), scanpath_length_mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pupil_size_norm_std (+0.00), fix_dur_mean_last...</td>\n",
       "      <td>pupil_size_norm_mean (-1.37), BCEA_68_mean (-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                              top_positive_features  \\\n",
       "0        0  BCEA_68_mean (+1.19), BCEA_95_mean (+1.19), pu...   \n",
       "1        1  fixation_duration_median_approx (+0.76), fix_d...   \n",
       "2        2  view_time_total_sum (+1.70), n_fix_last_third ...   \n",
       "3        3  fix_dur_mean_last_third (+1.44), fix_dur_mean_...   \n",
       "4        4  pupil_size_norm_std (+0.00), fix_dur_mean_last...   \n",
       "\n",
       "                               top_negative_features  \n",
       "0  fixation_duration_median_approx (-0.72), fix_d...  \n",
       "1  n_fix_first_third (-0.66), number_of_fixations...  \n",
       "2  fix_dur_mean_last_third (-1.23), fixation_dura...  \n",
       "3  n_fix_first_third (-1.02), scanpath_length_mea...  \n",
       "4  pupil_size_norm_mean (-1.37), BCEA_68_mean (-1...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature profiles and auto-explanations\n",
    "# Compute cluster centroids in scaled space and z-score by feature\n",
    "assert 'km' in globals() and 'feature_cols' in globals(), 'Run clustering first.'\n",
    "\n",
    "centroids_scaled = km.cluster_centers_\n",
    "centroids_scaled_df = pd.DataFrame(centroids_scaled, columns=feature_cols)\n",
    "# z-score across clusters (per feature) for comparability\n",
    "centroids_z = (centroids_scaled_df - centroids_scaled_df.mean(axis=0)) / (centroids_scaled_df.std(axis=0) + 1e-9)\n",
    "centroids_z['cluster'] = np.arange(centroids_scaled_df.shape[0])\n",
    "centroids_z = centroids_z.set_index('cluster').sort_index()\n",
    "\n",
    "plt.figure(figsize=(max(8, 0.5*len(feature_cols)), 1.2*len(centroids_z)))\n",
    "sns.heatmap(centroids_z, cmap='coolwarm', center=0, cbar_kws={'label':'z-score (vs other clusters)'})\n",
    "plt.title('Cluster feature profiles (z-scored centroids)')\n",
    "plt.xlabel('feature')\n",
    "plt.ylabel('cluster')\n",
    "plt.tight_layout()\n",
    "heatmap_out = out_dir / 'cluster_feature_profiles_heatmap.png'\n",
    "plt.savefig(heatmap_out, dpi=150)\n",
    "plt.close()\n",
    "print(f'Saved {heatmap_out}')\n",
    "\n",
    "# Auto-generate short per-cluster explanations based on top +/- features\n",
    "explanations = []\n",
    "for c in range(centroids_z.shape[0]):\n",
    "    row = centroids_z.loc[c]\n",
    "    top_pos = row.sort_values(ascending=False).head(3)\n",
    "    top_neg = row.sort_values(ascending=True).head(3)\n",
    "    pos_feats = \", \".join([f\"{k} (+{v:.2f})\" for k, v in top_pos.items()])\n",
    "    neg_feats = \", \".join([f\"{k} ({v:.2f})\" for k, v in top_neg.items()])\n",
    "    explanations.append({\n",
    "        'cluster': c,\n",
    "        'top_positive_features': pos_feats,\n",
    "        'top_negative_features': neg_feats,\n",
    "    })\n",
    "\n",
    "exp_df = pd.DataFrame(explanations)\n",
    "exp_out = out_dir / 'cluster_explanations.csv'\n",
    "exp_df.to_csv(exp_out, index=False)\n",
    "print(f'Saved {exp_out}')\n",
    "exp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
