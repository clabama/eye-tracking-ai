{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a53bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Setup\n",
    "# ==========================================\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99bd729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\fixations\n",
      "Using data_dir=c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\fixations\n",
      "Output: ./feature_engineering_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. Konfiguration\n",
    "# ==========================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Try common relative locations and an explicit project-root path\n",
    "cwd = Path.cwd()\n",
    "candidates = [\n",
    "    cwd / \"fixations\",\n",
    "    cwd.parent / \"fixations\",\n",
    "    cwd.parent.parent / \"fixations\",\n",
    "    Path(\"../fixations\"),\n",
    "    Path(\"../../fixations\"),\n",
    "    Path(\"./../fixations\"),\n",
    "    Path(\"./fixations\"),\n",
    "    Path(r\"c:\\Users\\SWixforth\\Uni\\eye-tracking-ai\\fixations\"),\n",
    "]\n",
    "\n",
    "DEFAULT_DIRS = [str(p) for p in candidates]\n",
    "data_dir = None\n",
    "for d in DEFAULT_DIRS:\n",
    "    if os.path.isdir(d):\n",
    "        data_dir = d\n",
    "        break\n",
    "\n",
    "# Fallback: walk up a few parents to find a 'fixations' folder\n",
    "if data_dir is None:\n",
    "    cur = cwd\n",
    "    for _ in range(6):\n",
    "        candidate = cur / \"fixations\"\n",
    "        if candidate.is_dir():\n",
    "            data_dir = str(candidate)\n",
    "            break\n",
    "        cur = cur.parent\n",
    "\n",
    "if data_dir is None:\n",
    "    raise FileNotFoundError(\"Kein Datenordner 'fixations' gefunden. Bitte Pfad anpassen.\")\n",
    "\n",
    "output_dir = \"./\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(data_dir)\n",
    "# Label-Reihenfolge\n",
    "BINARY_LABEL_ORDER = [\"meme\", \"ort\", \"person\", \"politik\", \"text\"]\n",
    "\n",
    "# Regex zum Parsen von Dateinamen: P000_id001_meme_10000.csv\n",
    "FNAME_RE = re.compile(r\"^P(?P<participant>\\d+)_id(?P<image>\\d+)(?:_(?P<basecat>[A-Za-z]+))?(?:_(?P<bin>[01]+))?\\.csv$\")\n",
    "\n",
    "summary_csv = os.path.join(output_dir, \"feature_engineering_summary.csv\")\n",
    "print(f\"Using data_dir={data_dir}\\nOutput: {summary_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cabcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Hilfsfunktionen\n",
    "# ==========================================\n",
    "def parse_filename_meta(fname: str) -> Dict[str, Optional[str]]:\n",
    "    name = os.path.basename(fname)\n",
    "    m = FNAME_RE.match(name)\n",
    "    meta = {\"participant\": None, \"image_id\": None, \"base_category\": None, \"binary_code\": None}\n",
    "    if m:\n",
    "        meta[\"participant\"] = m.group(\"participant\")\n",
    "        meta[\"image_id\"] = m.group(\"image\")\n",
    "        bc = m.group(\"basecat\")\n",
    "        meta[\"base_category\"] = bc.lower() if bc else None\n",
    "        meta[\"binary_code\"] = m.group(\"bin\")\n",
    "    return meta\n",
    "\n",
    "def labels_from_binary_code(code: Optional[str]) -> Dict[str, int]:\n",
    "    out = {k: 0 for k in BINARY_LABEL_ORDER}\n",
    "    if not code:\n",
    "        return out\n",
    "    bits = list(code.strip())\n",
    "    if len(bits) >= len(BINARY_LABEL_ORDER):\n",
    "        bits = bits[-len(BINARY_LABEL_ORDER):]\n",
    "    else:\n",
    "        bits = [\"0\"] * (len(BINARY_LABEL_ORDER) - len(bits)) + bits\n",
    "    for lbl, b in zip(BINARY_LABEL_ORDER, bits):\n",
    "        out[lbl] = int(b)\n",
    "    return out\n",
    "\n",
    "def labels_from_weight_cols(df: pd.DataFrame) -> Dict[str, float]:\n",
    "    weights = {}\n",
    "    for lbl in BINARY_LABEL_ORDER:\n",
    "        col = f\"weight_{lbl}\"\n",
    "        if col in df.columns:\n",
    "            val = df[col].dropna()\n",
    "            weights[lbl] = float(val.iloc[0]) if len(val) else float(\"nan\")\n",
    "        else:\n",
    "            weights[lbl] = float(\"nan\")\n",
    "    return weights\n",
    "\n",
    "def pick_primary_label(base_category: Optional[str], bin_labels: Dict[str, int], weight_labels: Dict[str, float]) -> Optional[str]:\n",
    "    if base_category in BINARY_LABEL_ORDER:\n",
    "        return base_category\n",
    "    best_lbl, best_w = None, -np.inf\n",
    "    for lbl, w in weight_labels.items():\n",
    "        if pd.notna(w) and w > best_w:\n",
    "            best_lbl, best_w = lbl, w\n",
    "    if best_lbl is not None and best_w != -np.inf and pd.notna(best_w):\n",
    "        return best_lbl\n",
    "    for lbl in BINARY_LABEL_ORDER:\n",
    "        if bin_labels.get(lbl, 0) == 1:\n",
    "            return lbl\n",
    "    return None\n",
    "\n",
    "def bcea(x: np.ndarray, y: np.ndarray, p: float = 0.68) -> float:\n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        return float(\"nan\")\n",
    "    sx, sy = np.std(x, ddof=1), np.std(y, ddof=1)\n",
    "    if sx == 0 or sy == 0:\n",
    "        return float(\"nan\")\n",
    "    rho = np.corrcoef(x, y)[0, 1]\n",
    "    rho = 0.0 if np.isnan(rho) else rho\n",
    "    k = 3.0 if p >= 0.95 else 1.14\n",
    "    return 2 * math.pi * k * sx * sy * math.sqrt(max(0.0, 1 - rho**2))\n",
    "\n",
    "def compute_scanpath_length(xs: np.ndarray, ys: np.ndarray) -> float:\n",
    "    if len(xs) < 2:\n",
    "        return 0.0\n",
    "    return float(np.sum(np.sqrt(np.diff(xs)**2 + np.diff(ys)**2)))\n",
    "\n",
    "def compute_image_level_features(df: pd.DataFrame, fname: str) -> Dict:\n",
    "    if df.empty:\n",
    "        return {\"file\": os.path.basename(fname), \"n_fix\": 0}\n",
    "\n",
    "    weight_labels = labels_from_weight_cols(df)\n",
    "\n",
    "    xs = df[\"x\"].astype(float).values if \"x\" in df.columns else np.array([])\n",
    "    ys = df[\"y\"].astype(float).values if \"y\" in df.columns else np.array([])\n",
    "    durs = df[\"duration\"].astype(float).values if \"duration\" in df.columns else np.array([])\n",
    "\n",
    "    start_min = float(df[\"start_time\"].min()) if \"start_time\" in df.columns else float(\"nan\")\n",
    "    end_max = float(df[\"end_time\"].max()) if \"end_time\" in df.columns else float(\"nan\")\n",
    "    view_time_total = float(max(0.0, end_max - start_min)) if not (math.isnan(end_max) or math.isnan(start_min)) else float(\"nan\")\n",
    "\n",
    "    n_fix = int(len(df))\n",
    "    sum_dur = float(np.nansum(durs)) if len(durs) else float(\"nan\")\n",
    "    mean_dur = float(np.nanmean(durs)) if len(durs) else float(\"nan\")\n",
    "    median_dur = float(np.nanmedian(durs)) if len(durs) else float(\"nan\")\n",
    "\n",
    "    out = {\n",
    "        \"file\": os.path.basename(fname),\n",
    "        \"n_fix\": n_fix,\n",
    "        \"view_time_total\": view_time_total,\n",
    "        \"sum_fix_dur\": sum_dur,\n",
    "        \"fix_dur_mean\": mean_dur,\n",
    "        \"fix_dur_median\": median_dur,\n",
    "        \"scanpath_length\": compute_scanpath_length(xs, ys),\n",
    "        \"bcea_68\": bcea(xs, ys, p=0.68),\n",
    "        \"bcea_95\": bcea(xs, ys, p=0.95),\n",
    "    }\n",
    "\n",
    "    meta = parse_filename_meta(fname)\n",
    "    bin_labels = labels_from_binary_code(meta.get(\"binary_code\"))\n",
    "    primary_label = pick_primary_label(meta.get(\"base_category\"), bin_labels, weight_labels)\n",
    "\n",
    "    out[\"participant\"] = meta.get(\"participant\")\n",
    "    out[\"image_id\"] = meta.get(\"image_id\")\n",
    "    out[\"primary_label\"] = primary_label\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c3d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7362 CSV files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>n_fix</th>\n",
       "      <th>view_time_total</th>\n",
       "      <th>sum_fix_dur</th>\n",
       "      <th>fix_dur_mean</th>\n",
       "      <th>fix_dur_median</th>\n",
       "      <th>scanpath_length</th>\n",
       "      <th>bcea_68</th>\n",
       "      <th>bcea_95</th>\n",
       "      <th>participant</th>\n",
       "      <th>image_id</th>\n",
       "      <th>primary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P000_id001_meme_10000.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>5,640.8540</td>\n",
       "      <td>4,393.5770</td>\n",
       "      <td>313.8269</td>\n",
       "      <td>282.8405</td>\n",
       "      <td>2,586.8320</td>\n",
       "      <td>46,378.1194</td>\n",
       "      <td>122,047.6827</td>\n",
       "      <td>000</td>\n",
       "      <td>001</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000_id002_meme_10000.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>6,955.2670</td>\n",
       "      <td>6,373.7550</td>\n",
       "      <td>335.4608</td>\n",
       "      <td>249.5970</td>\n",
       "      <td>1,841.8719</td>\n",
       "      <td>29,754.6381</td>\n",
       "      <td>78,301.6793</td>\n",
       "      <td>000</td>\n",
       "      <td>002</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000_id003_meme_10000.csv</td>\n",
       "      <td>14</td>\n",
       "      <td>5,940.5040</td>\n",
       "      <td>5,241.2310</td>\n",
       "      <td>374.3736</td>\n",
       "      <td>307.7835</td>\n",
       "      <td>2,159.6009</td>\n",
       "      <td>46,590.8309</td>\n",
       "      <td>122,607.4496</td>\n",
       "      <td>000</td>\n",
       "      <td>003</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P000_id004_meme_10000.csv</td>\n",
       "      <td>19</td>\n",
       "      <td>6,223.4440</td>\n",
       "      <td>5,025.3020</td>\n",
       "      <td>264.4896</td>\n",
       "      <td>232.9670</td>\n",
       "      <td>2,623.9104</td>\n",
       "      <td>77,827.9004</td>\n",
       "      <td>204,810.2641</td>\n",
       "      <td>000</td>\n",
       "      <td>004</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P000_id005_meme_10000.csv</td>\n",
       "      <td>18</td>\n",
       "      <td>5,458.0030</td>\n",
       "      <td>4,842.6010</td>\n",
       "      <td>269.0334</td>\n",
       "      <td>224.6735</td>\n",
       "      <td>2,371.0968</td>\n",
       "      <td>60,326.9096</td>\n",
       "      <td>158,755.0254</td>\n",
       "      <td>000</td>\n",
       "      <td>005</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        file  n_fix  view_time_total  sum_fix_dur  \\\n",
       "0  P000_id001_meme_10000.csv     14       5,640.8540   4,393.5770   \n",
       "1  P000_id002_meme_10000.csv     19       6,955.2670   6,373.7550   \n",
       "2  P000_id003_meme_10000.csv     14       5,940.5040   5,241.2310   \n",
       "3  P000_id004_meme_10000.csv     19       6,223.4440   5,025.3020   \n",
       "4  P000_id005_meme_10000.csv     18       5,458.0030   4,842.6010   \n",
       "\n",
       "   fix_dur_mean  fix_dur_median  scanpath_length     bcea_68      bcea_95  \\\n",
       "0      313.8269        282.8405       2,586.8320 46,378.1194 122,047.6827   \n",
       "1      335.4608        249.5970       1,841.8719 29,754.6381  78,301.6793   \n",
       "2      374.3736        307.7835       2,159.6009 46,590.8309 122,607.4496   \n",
       "3      264.4896        232.9670       2,623.9104 77,827.9004 204,810.2641   \n",
       "4      269.0334        224.6735       2,371.0968 60,326.9096 158,755.0254   \n",
       "\n",
       "  participant image_id primary_label  \n",
       "0         000      001          meme  \n",
       "1         000      002          meme  \n",
       "2         000      003          meme  \n",
       "3         000      004          meme  \n",
       "4         000      005          meme  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. Dateien einlesen und Features berechnen\n",
    "# ==========================================\n",
    "csv_files = sorted(glob.glob(os.path.join(data_dir, \"*.csv\")))\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "rows = []\n",
    "for fp in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "        rows.append(compute_image_level_features(df, fp))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler in {fp}: {e}\")\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b766256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert unter: ./feature_engineering_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>7362</td>\n",
       "      <td>7362</td>\n",
       "      <td>P000_id001_meme_10000.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_fix</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.1788</td>\n",
       "      <td>12.8863</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>67.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view_time_total</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,590.1730</td>\n",
       "      <td>3,777.8584</td>\n",
       "      <td>115.4320</td>\n",
       "      <td>6,355.9820</td>\n",
       "      <td>8,469.3400</td>\n",
       "      <td>14,343.6272</td>\n",
       "      <td>15,142.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_fix_dur</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7,649.8224</td>\n",
       "      <td>3,371.1205</td>\n",
       "      <td>115.4320</td>\n",
       "      <td>5,093.3483</td>\n",
       "      <td>6,776.1500</td>\n",
       "      <td>10,703.7720</td>\n",
       "      <td>14,626.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_dur_mean</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.7501</td>\n",
       "      <td>77.3289</td>\n",
       "      <td>115.4290</td>\n",
       "      <td>218.1892</td>\n",
       "      <td>255.9649</td>\n",
       "      <td>301.6773</td>\n",
       "      <td>1,595.7598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fix_dur_median</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.4443</td>\n",
       "      <td>51.4420</td>\n",
       "      <td>115.4290</td>\n",
       "      <td>191.6980</td>\n",
       "      <td>216.4630</td>\n",
       "      <td>249.6010</td>\n",
       "      <td>948.3900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scanpath_length</th>\n",
       "      <td>7,362.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,192.8585</td>\n",
       "      <td>1,422.2452</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2,189.5847</td>\n",
       "      <td>3,003.0312</td>\n",
       "      <td>4,075.4114</td>\n",
       "      <td>10,622.9587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcea_68</th>\n",
       "      <td>7,320.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86,419.6669</td>\n",
       "      <td>42,640.4296</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>53,701.8835</td>\n",
       "      <td>83,703.3933</td>\n",
       "      <td>112,924.3429</td>\n",
       "      <td>286,166.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcea_95</th>\n",
       "      <td>7,320.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227,420.1761</td>\n",
       "      <td>112,211.6568</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>141,320.7460</td>\n",
       "      <td>220,272.0876</td>\n",
       "      <td>297,169.3234</td>\n",
       "      <td>753,070.1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant</th>\n",
       "      <td>7362</td>\n",
       "      <td>49</td>\n",
       "      <td>000</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <td>7362</td>\n",
       "      <td>152</td>\n",
       "      <td>001</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_label</th>\n",
       "      <td>7362</td>\n",
       "      <td>5</td>\n",
       "      <td>person</td>\n",
       "      <td>2807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique                        top  freq  \\\n",
       "file                  7362   7362  P000_id001_meme_10000.csv     1   \n",
       "n_fix           7,362.0000    NaN                        NaN   NaN   \n",
       "view_time_total 7,362.0000    NaN                        NaN   NaN   \n",
       "sum_fix_dur     7,362.0000    NaN                        NaN   NaN   \n",
       "fix_dur_mean    7,362.0000    NaN                        NaN   NaN   \n",
       "fix_dur_median  7,362.0000    NaN                        NaN   NaN   \n",
       "scanpath_length 7,362.0000    NaN                        NaN   NaN   \n",
       "bcea_68         7,320.0000    NaN                        NaN   NaN   \n",
       "bcea_95         7,320.0000    NaN                        NaN   NaN   \n",
       "participant           7362     49                        000   152   \n",
       "image_id              7362    152                        001    49   \n",
       "primary_label         7362      5                     person  2807   \n",
       "\n",
       "                        mean          std      min          25%          50%  \\\n",
       "file                     NaN          NaN      NaN          NaN          NaN   \n",
       "n_fix                29.1788      12.8863   1.0000      19.0000      27.0000   \n",
       "view_time_total   9,590.1730   3,777.8584 115.4320   6,355.9820   8,469.3400   \n",
       "sum_fix_dur       7,649.8224   3,371.1205 115.4320   5,093.3483   6,776.1500   \n",
       "fix_dur_mean        267.7501      77.3289 115.4290     218.1892     255.9649   \n",
       "fix_dur_median      225.4443      51.4420 115.4290     191.6980     216.4630   \n",
       "scanpath_length   3,192.8585   1,422.2452   0.0000   2,189.5847   3,003.0312   \n",
       "bcea_68          86,419.6669  42,640.4296   0.0000  53,701.8835  83,703.3933   \n",
       "bcea_95         227,420.1761 112,211.6568   0.0000 141,320.7460 220,272.0876   \n",
       "participant              NaN          NaN      NaN          NaN          NaN   \n",
       "image_id                 NaN          NaN      NaN          NaN          NaN   \n",
       "primary_label            NaN          NaN      NaN          NaN          NaN   \n",
       "\n",
       "                         75%          max  \n",
       "file                     NaN          NaN  \n",
       "n_fix                38.0000      67.0000  \n",
       "view_time_total  14,343.6272  15,142.6100  \n",
       "sum_fix_dur      10,703.7720  14,626.7200  \n",
       "fix_dur_mean        301.6773   1,595.7598  \n",
       "fix_dur_median      249.6010     948.3900  \n",
       "scanpath_length   4,075.4114  10,622.9587  \n",
       "bcea_68         112,924.3429 286,166.6688  \n",
       "bcea_95         297,169.3234 753,070.1811  \n",
       "participant              NaN          NaN  \n",
       "image_id                 NaN          NaN  \n",
       "primary_label            NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 5. Ergebnis speichern\n",
    "# ==========================================\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "print(f\"Gespeichert unter: {summary_csv}\")\n",
    "summary.describe(include=\"all\").transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36396987",
   "metadata": {},
   "source": [
    "### Interpreting the summary.describe(include=\"all\").transpose() output\n",
    "\n",
    "This table shows descriptive statistics per feature (each row is one original column from `summary`).\n",
    "\n",
    "- Numeric columns include:\n",
    "  - count: number of files with a non-missing value\n",
    "  - mean, std: average and standard deviation across files\n",
    "  - min, 25%, 50% (median), 75%, max: distribution quantiles and extremes\n",
    "\n",
    "- Non-numeric (object/category) columns include:\n",
    "  - count: number of files (non-missing)\n",
    "  - unique: number of distinct values\n",
    "  - top: most frequent value\n",
    "  - freq: frequency of the most frequent value\n",
    "\n",
    "- Not applicable statistics appear as NaN.\n",
    "\n",
    "Notes for key features in this notebook:\n",
    "- n_fix: number of fixations in a file (rows per CSV).\n",
    "- view_time_total: end_time − start_time (total viewing time per file).\n",
    "- sum_fix_dur, fix_dur_mean, fix_dur_median: sum/mean/median of fixation durations in the file.\n",
    "- scanpath_length: total path length across successive fixations (in the same units as x/y).\n",
    "- bcea_68, bcea_95: bivariate confidence ellipse area (approx. 68% and 95%).\n",
    "- file, participant, image_id, primary_label: categorical metadata summarized with top/unique/freq.\n",
    "\n",
    "Tip: Sort rows by a statistic of interest (e.g., click the header for `mean`) to see which features are highest or most variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
